{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# !pip install requests_html\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "import pdfplumber\n",
    "from IPython.display import display, HTML, Javascript\n",
    "import ipywidgets as widgets\n",
    "from selenium import webdriver\n",
    "import webbrowser\n",
    "from IPython.display import clear_output\n",
    "import os, pickle\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeData():\n",
    "    \"\"\"\n",
    "    Python tool to scrap text data from different languages. 3 options available:\n",
    "    \n",
    "    - scrape from link: provided with a link, the tool scrapes through the text body from the webpage \n",
    "      corresponding to the link.\n",
    "      \n",
    "    - scrape from keyword: provided with a keyword, the tool performs a google search and retrieves text from \n",
    "      a priority domain webpage(eg: wikipedia) or top google search result.\n",
    "      \n",
    "    - scrape from document: provided with a pdf document, the tools accesses the text using pdfplumber \n",
    "      python package. Note that some portion of the text may not be returned properly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialise parameters for google search and priority website \n",
    "        \"\"\"\n",
    "        \n",
    "        self.parser = 'html.parser'\n",
    "        self.tld = 'co.in'\n",
    "        self.search_num = 10\n",
    "        self.search_stop = 10\n",
    "        self.pause = 2\n",
    "        self.search_priority = 'wikipedia'\n",
    "        self.auto_return_index = 0\n",
    "        \n",
    "    def read_from_link(self, link, replace_list=['\\n']):\n",
    "        \"\"\"\n",
    "        This function accesses the text content from a webpage link using beautiful soup. To clean the text, \n",
    "        provide the list of charecters to be removed in replace_list.\n",
    "        This may not work for js webpages, cloudfare ddos protected pages etc\n",
    "        \"\"\"\n",
    "        #use header if access is denied.\n",
    "#         headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) '\\\n",
    "#            'AppleWebKit/537.36 (KHTML, like Gecko) '\\\n",
    "#            'Chrome/75.0.3770.80 Safari/537.36'}\n",
    "\n",
    "#         page = requests.get(link, headers=headers)\n",
    "        page = requests.get(link)\n",
    "        soup = BeautifulSoup(page.content, self.parser)\n",
    "        data = []\n",
    "        for i in range(len(soup.find_all('p'))):\n",
    "            text = soup.find_all('p')[i].get_text()\n",
    "            for j in range(len(replace_list)):\n",
    "                text = text.replace(replace_list[j],'')\n",
    "            if len(text)>0:\n",
    "                data.append(text)\n",
    "        return data\n",
    "\n",
    "    def google_search(self, search_keyword, priority=None):\n",
    "        \"\"\"\n",
    "        This function performs google search on the input keyword. Priority can be provided to a particular \n",
    "        website (Eg: wikipedia) \n",
    "        \"\"\"\n",
    "        search_links = []\n",
    "        for link in search(search_keyword, \n",
    "                           tld=self.tld, \n",
    "                           num=self.search_num, \n",
    "                           stop=self.search_stop, \n",
    "                           pause=self.pause):\n",
    "            search_links.append(link)\n",
    "            \n",
    "            if priority is not None:\n",
    "                if self.search_priority in link:\n",
    "                    return link\n",
    "        return search_links[self.auto_return_index]\n",
    "                \n",
    "    \n",
    "    def read_from_doc(self, document):\n",
    "        \"\"\"\n",
    "        This function extracts text from pdf using pdfplumber tool.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        with pdfplumber.open(document) as pdf:\n",
    "            for i in range(len(pdf.pages)):\n",
    "                page = pdf.pages[i]\n",
    "                text = page.extract_text()\n",
    "                if text is not None:\n",
    "                    text = text.replace('\\n', ' ')\n",
    "                    data.append(text) \n",
    "        return data\n",
    "    \n",
    "    def read_page(self, search_keyword=None, link=None, document=None):\n",
    "        if search_keyword == link == document == None:\n",
    "            raise Exception('Provide link, keyword or document to scrape from')\n",
    "            \n",
    "        if search_keyword is not None:\n",
    "            keyword_link = self.google_search(search_keyword, priority=self.search_priority)\n",
    "            text = self.read_from_link(keyword_link)\n",
    "            return(text)\n",
    "            \n",
    "        if link:\n",
    "            text = self.read_from_link(link)\n",
    "            return(text)\n",
    "                \n",
    "        if document:\n",
    "            text = self.read_from_doc(document)\n",
    "            print(f'{len(text)} pages found')\n",
    "            return(text)\n",
    "            \n",
    "scrape_tool = ScrapeData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Read from english website</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scrape_tool.read_page(link='https://en.wikipedia.org/wiki/Agriculture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Read from english keyword</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_tool.read_page(search_keyword='agriculture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Read from english pdf document</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_tool.read_page(document='document_name.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read from list of links with GUI</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveScrappingGUI():\n",
    "    def __init__(self, links):\n",
    "        if not isinstance(links, list):\n",
    "            raise Exception('link input shoudl be present as a python list')\n",
    "        self.linkIdx = 0\n",
    "        self.links = links\n",
    "        self.approvedList = {}\n",
    "        self.storedText = {}\n",
    "        self.defaultColor  = '#EEEEEE'\n",
    "        self.approvedColor = 'lightgreen'\n",
    "        self.rejectedColor = '#FF4500'\n",
    "        self.nextButton = widgets.Button(description = 'Next')\n",
    "        self.approve = widgets.Button(description = 'Approve', disabled=True)\n",
    "        self.reject = widgets.Button(description = 'Reject', disabled=True)\n",
    "        self.nextButton.add_class(\"red_label\")\n",
    "        self.approve.add_class(\"red_label\")\n",
    "        self.reject.add_class(\"red_label\")\n",
    "        self.output = widgets.Output()\n",
    "        display(widgets.HBox((self.nextButton, self.approve,self.reject )), self.output, \n",
    "        HTML(\"<style>.red_label { font-weight: bold}</style>\"),\n",
    "        HTML(\"<style>.red_label { font-family:calibri}</style>\"),\n",
    "        HTML(\"<style>.red_label { font-size:16px}</style>\"))\n",
    "        \n",
    "    def on_button_clicked_approve(self, b):\n",
    "        with self.output:\n",
    "            self.nextButton.disabled = False\n",
    "            self.approve.style.button_color = self.approvedColor\n",
    "            self.reject.style.button_color = self.defaultColor\n",
    "            self.approvedList[self.links[self.linkIdx-1]] = True\n",
    "                \n",
    "    def on_button_clicked_reject(self, b):\n",
    "        with self.output:\n",
    "            self.nextButton.disabled = False\n",
    "            self.approve.style.button_color = self.defaultColor\n",
    "            self.reject.style.button_color = self.rejectedColor\n",
    "            self.approvedList[self.links[self.linkIdx-1]] = False\n",
    "                \n",
    "    def on_button_clicked(self, b):\n",
    "        with self.output:\n",
    "            if  self.linkIdx == len(self.links):\n",
    "                clear_output()\n",
    "                print('All links visited. Approved link can be accessed with \"gui.approvedList\"')\n",
    "                self.reject.disabled = True\n",
    "                self.approve.disabled = True\n",
    "                self.nextButton.disabled = True\n",
    "                self.reject.style.button_color = self.defaultColor\n",
    "                self.approve.style.button_color = self.defaultColor\n",
    "            else:\n",
    "                clear_output()\n",
    "                self.reject.disabled = True\n",
    "                self.approve.disabled = True\n",
    "                self.nextButton.disabled = True\n",
    "                self.reject.style.button_color = self.defaultColor\n",
    "                self.approve.style.button_color = self.defaultColor\n",
    "                print('Extracting..')\n",
    "                text = scrape_tool.read_page(link=self.links[self.linkIdx])\n",
    "                clear_output()\n",
    "                self.storedText[self.links[self.linkIdx]] = text\n",
    "                for para in text:\n",
    "                    print(para, '\\n')\n",
    "                webbrowser.open(self.links[self.linkIdx])\n",
    "                self.reject.disabled = False\n",
    "                self.approve.disabled = False\n",
    "                self.linkIdx += 1\n",
    "            \n",
    "    def start(self):\n",
    "        self.approve.on_click(self.on_button_clicked_approve)\n",
    "        self.reject.on_click(self.on_button_clicked_reject)\n",
    "        self.nextButton.on_click(self.on_button_clicked)\n",
    "    \n",
    "    def save(self, path):\n",
    "        existingFiles = set(os.listdir(path))\n",
    "        for key, item in self.approvedList.items():\n",
    "            if item == True:                \n",
    "                    name = os.path.join(path, 'extracted_file_'+str(time.time())+'.json')\n",
    "                    if name in existingFiles:\n",
    "                        raise Exception('A file already exists in the save path for the current file. '\\\n",
    "                                        'Change saving procedure for your setup')\n",
    "                    with open(name, 'w') as f: \n",
    "                        json.dump({'link':key,\n",
    "                                  'text':self.storedText[key]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links = ['https://en.wikipedia.org/wiki/Agriculture', 'https://www.bbc.com/hindi/india-56901831',\n",
    "        'https://en.wikipedia.org/wiki/Main_Page']\n",
    "\n",
    "#load links from csv into a list\n",
    "scrape_tool = ScrapeData()\n",
    "gui = ActiveScrappingGUI(links)\n",
    "gui.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://en.wikipedia.org/wiki/Agriculture': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui.approvedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store this as .pickle if rejected links are processed at a later time.\n",
    "linkStatusPath = 'status.pickle'\n",
    "with open(linkStatusPath, 'wb') as handle:\n",
    "    pickle.dump(gui.approvedList, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Save approved text </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide your folder path\n",
    "gui.save(path='saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = json.load('saved/extracted_file_1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example on how to proceed with rejected links (Work In Progress)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class HandleRejects():\n",
    "    def __init__(self, storedGUIStatusDict, openWebPage = True, ):\n",
    "        self.approve = widgets.Button(description = 'Approve Changes')\n",
    "        self.refresh = widgets.Button(description = 'Refresh Changes')\n",
    "        self.discard = widgets.Button(description = 'Unable to process')\n",
    "        self.output = widgets.Output()\n",
    "        self.openWebPage = openWebPage\n",
    "        self.defaultColor  = '#EEEEEE'\n",
    "        self.approve.disabled = True\n",
    "        self.discard.disabled = True\n",
    "        self.approve.add_class(\"layout\")\n",
    "        self.refresh.add_class(\"layout\")\n",
    "        self.discard.add_class(\"layout\")\n",
    "        with open(linkStatusPath, 'rb') as handle:\n",
    "            self.statusDct = pickle.load(handle)\n",
    "        self.resolvedLinks = {}\n",
    "        self.discardedLinks = {}\n",
    "        self.initalVal = None\n",
    "        self.initalVal = self.reportStatus()\n",
    "        self.linkIdx = 0\n",
    "        self.visitSet = set()\n",
    "        self.linkFromStatus = [key for key, item in self.statusDct.items() if item == False]\n",
    "        \n",
    "    def reportStatus(self):\n",
    "        if self.initalVal == None:\n",
    "            toBeResolved = sum([1 if item == False else 0 for key, item in self.statusDct.items()])\n",
    "            return toBeResolved\n",
    "        else:\n",
    "            self.remainingCount = self.initalVal - len(self.resolvedLinks) - len(self.discardedLinks)\n",
    "            print(f'{self.remainingCount}/{self.initalVal} links left to be resolved')\n",
    "    \n",
    "    def on_button_clicked_approve(self, b):\n",
    "        with self.output:\n",
    "            self.approve.style.button_color = self.defaultColor\n",
    "            self.resolvedLinks[self.currentLink] = self.currentText\n",
    "            self.linkIdx += 1 \n",
    "            clear_output()\n",
    "            print(f'Text extracted from {self.currentLink} approved')\n",
    "            self.reportStatus()\n",
    "            self.discard.disabled = True\n",
    "            self.approve.disabled = True\n",
    "    \n",
    "    def on_button_clicked_discard(self, b):\n",
    "        with self.output:\n",
    "            self.discard.style.button_color = self.defaultColor\n",
    "            self.discardedLinks[self.currentLink] = self.currentText\n",
    "            self.linkIdx += 1 \n",
    "            clear_output()\n",
    "            print(f'Text extracted from {self.currentLink} needs manual inspection. Unable to proceed with web scraping code')\n",
    "            self.reportStatus()\n",
    "            self.approve.disabled = True\n",
    "            self.discard.disabled = True\n",
    "            \n",
    "    def on_button_clicked_refresh(self, b):\n",
    "        with self.output:\n",
    "            if len(self.linkFromStatus) == 0:\n",
    "                raise Exception('No sentences dound in dict')\n",
    "            self.approve.disabled = False\n",
    "            self.discard.disabled = False\n",
    "            self.reportStatus()\n",
    "            print('Extracting..')\n",
    "            if self.linkIdx >= len(self.linkFromStatus):\n",
    "                clear_output()\n",
    "                self.discard.disabled = True\n",
    "                self.approve.disabled = True\n",
    "                self.refresh.disabled = True\n",
    "                raise Exception('All links visited. : )')\n",
    "            self.currentLink = self.linkFromStatus[self.linkIdx]\n",
    "            if self.currentLink not in self.resolvedLinks.keys():\n",
    "                if self.currentLink not in self.visitSet:\n",
    "                    self.visitSet.add(self.currentLink)\n",
    "#                     webbrowser.open(self.currentLink)\n",
    "                    print(self.currentLink)\n",
    "                self.currentText = self.readFn(self.currentLink)\n",
    "                clear_output()\n",
    "                for line in self.currentText:\n",
    "                    print(line, '\\n')\n",
    "    \n",
    "    def start(self, readFn):\n",
    "        display(widgets.HBox((self.approve, self.refresh, self.discard)), self.output, \n",
    "        HTML(\"<style>.layout { font-weight: bold}</style>\"),\n",
    "        HTML(\"<style>.layout { font-family:calibri}</style>\"),\n",
    "        HTML(\"<style>.layout { font-size:16px}</style>\"))\n",
    "        self.readFn = readFn\n",
    "        self.refresh.on_click(self.on_button_clicked_refresh)\n",
    "        self.approve.on_click(self.on_button_clicked_approve)\n",
    "        self.discard.on_click(self.on_button_clicked_discard)\n",
    "    \n",
    "    def save(self, path):\n",
    "        existingFiles = set(os.listdir(path))\n",
    "        for key, item in self.resolvedLinks.items():\n",
    "            if item == True:                \n",
    "                    name = os.path.join(path, 'extracted_file_'+str(time.time())+'.json')\n",
    "                    if name in existingFiles:\n",
    "                        raise Exception('A file already exists in the save path for the current file. '\\\n",
    "                                        'Change saving procedure for your setup')\n",
    "                    with open(name, 'w') as f: \n",
    "                        json.dump({'link':key,\n",
    "                                  'text':self.storedText[key]}, f)\n",
    "   \n",
    "    def saveDiscarded(self, path):\n",
    "        with open(path, 'w') as f:\n",
    "            data = list(self.discardedLinks.keys())\n",
    "            for line in data:\n",
    "                f.write(line+'\\n')\n",
    "                \n",
    "linkStatusPath = 'status.pickle'\n",
    "handle = HandleRejects(storedGUIStatusDict=linkStatusPath);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd79860ea034c95be5f891ffc15a98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Approve Changes', disabled=True, style=ButtonStyle(), _dom_classes=('layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13b39a8bf244b1fb21c03d2ffe312a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.layout { font-weight: bold}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.layout { font-family:calibri}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.layout { font-size:16px}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_from_link_custom(link, replace_list=['\\n']):  \n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    data = []\n",
    "    for i in range(len(soup.find_all('p'))):\n",
    "        text = soup.find_all('p')[i].get_text()\n",
    "        for j in range(len(replace_list)):\n",
    "            text = text.replace(replace_list[j],'')\n",
    "        if len(text)>0:\n",
    "            data.append(text)\n",
    "    return data  \n",
    "\n",
    "handle.start(readFn=read_from_link_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['https://en.wikipedia.org/wiki/Agriculture'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resolved links with extracted text present here\n",
    "handle.resolvedLinks.keys()\n",
    "#links which need manual inspection present here\n",
    "# list(handle.discardedLinks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.save('saveResolved')\n",
    "handle.saveDiscarded('furtherInspection/day1links.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read from hindi webpage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_tool.read_page(link=\"https://hi.wikipedia.org/wiki/%E0%A4%95%E0%A5%83%E0%A4%B7%E0%A4%BF\")\n",
    "scrape_tool.read_page(link=\"https://www.bbc.com/hindi/india-56901831\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read from hindi document</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_tool.read_page(document='RedRidingHood-H-2mb.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read from kannada webpage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_tool.read_page(link=\"https://kn.wikipedia.org/wiki/%E0%B2%B8%E0%B2%BE%E0%B2%B5%E0%B2%AF%E0%B2%B5_%E0%B2%AC%E0%B3%87%E0%B2%B8%E0%B2%BE%E0%B2%AF\")\n",
    "scrape_tool.read_page(link=\"https://kannada.asianetnews.com/karnataka-districts/bjp-mla-g-somashekara-reddy-talks-lockdown-in-karnataka-grg-qs9n0r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://www.bbc.com/hindi/india-56901831',\n",
       " 'text': ['इमेज स्रोत, AFP',\n",
       "  '\"मैंने इस तरह के डरावने हालात इससे पहले कभी नहीं देखे थे. मुझे तो यक़ीन भी नहीं हो रहा है कि हमलोग भारत की राजधानी में हैं.\" यह कहना था जयंत मल्होत्रा का.',\n",
       "  'उन्होंने बीबीसी से बात करते हुए कहा, \"लोगों को ऑक्सीजन नहीं मिल रही है और वो जानवरों की तरह मर रहे हैं.\\'\\'',\n",
       "  'कोरोना वायरस के लक्षण क्या हैं और कैसे कर सकते हैं बचाव',\n",
       "  'कोरोना वैक्सीन: वो बातें जो आपको जाननी चाहिए',\n",
       "  'जयंत मल्होत्रा दिल्ली के एक श्मशान घाट में लोगों के अंतिम संस्कार में मदद करते हैं. दिल्ली के क़रीब-क़रीब सारे अस्पताल कोरोना मरीज़ों की रोज़ बढ़ती तादाद से जूझ रहे हैं. ',\n",
       "  'समाप्त',\n",
       "  'सोमवार को भारत में लगातार पाँचवे दिन भी तीन लाख से ज़्यादा नए मामले सामने आए हैं. इस समय दुनिया में सबसे ज़्यादा मामले रोज़ाना भारत में आ रहे हैं.',\n",
       "  'हालंकि मंगलवार को कोरोना संक्रमितों की संख्या में क़रीब 30 हज़ार की कमी देखी गई.',\n",
       "  'पिछले दो हफ़्ते में भारत में कोरोना संक्रमितों की संख्या में अप्रत्याशित उछाल देखी जा रही है वहीं चीन, अमेरिका और यूरोप के कई देशों में इस दौरान कोरोना से मरने वालों की संख्या में कमी आई है.',\n",
       "  'कई देश लॉकडाउन हटा रहे हैं. यूरोपीय यूनियन ने तो अमेरिका से आने वालों को इजाज़त देने के सभी संकेत दिए हैं, जिन्होंने कोरोना का टीका लगवा लिया है.',\n",
       "  'लेकिन क्या भारत में कोरोना के कारण ख़राब होते हालात दुनिया के लिए भी एक बड़ी समस्या बन सकते हैं?',\n",
       "  'इमेज स्रोत, Reuters',\n",
       "  'कोरोना के मरने वालों की संख्या लगातार बढ़ रही है. इसलिए श्मशान घाट में एक ही साथ कई शवों को जलाया जा रहा है.',\n",
       "  'इस साल फ़रवरी में रोज़ाना कोरोना संक्रमितों की संख्या क़रीब 12 हज़ार थी और मरने वालों की संख्या कुछ सौ थी, तब लोगों को उम्मीद हो गई थी कि भारत में कोरोना का सबसे बुरा दौर गुज़र चुका है.',\n",
       "  'लेकिन 17 अप्रैल के बाद से भारत में रोज़ाना दो लाख से ज़्यादा संक्रमण के मामले आ रहे हैं जबकि पिछले साल सितंबर में जब कोरोना अपने पीक पर था तब भारत में रोज़ाना क़रीब 93 हज़ार मामले आ रहे थे.',\n",
       "  'कोरोना वैक्सीन: क्या वैक्सीन लेने के बाद भी मुझे कोविड हो सकता है? ',\n",
       "  'कोविड-19 वैक्सीन कितनी सुरक्षित है? ',\n",
       "  'इस दौरान रोज़ाना मरने वालों की संख्या भी बढ़ी है जो 25 अप्रैल तक औसतन 2336 हो गई है. पिछले साल के पीक में रोज़ाना मरने वालों की लगभग दो गुना.',\n",
       "  'बीबीसी के स्वास्थ्य और विज्ञान संवाददाता जेम्स गैलाघर के अनुसार स्पष्ट है कि भारत संघर्ष कर रहा है. सामने जो डर सता रहा है वो मुझे उस समय की याद दिला रहा है जब कोरोना महामारी की शुरुआत हुई थी और लोगों को इसके बारे में कोई ज़्यादा जानकारी नहीं थी.',\n",
       "  'जेम्स कहते हैं, \"पूरे मेडिकल केयर से बाद भी कोरोना जानलेवा हो सकता है, लेकिन जब अस्पतालों में जगह भी नहीं है तब तो वो लोग भी मारे जाते हैं जिनकी ज़िंदगी शायद बचाई जा सकती थी.\"',\n",
       "  'दिल्ली में हालात ज़्यादा ख़राब हैं जहाँ एक भी आईसीयू बेड ख़ाली नहीं है.',\n",
       "  'इमेज स्रोत, AFP',\n",
       "  'दिल्ली के कई अस्पताल अब कोरोना मरीज़ों को एडमिट नहीं कर रहे हैं.',\n",
       "  'कई अस्पताल नए मरीज़ों को एडमिट करने से मना कर रहे हैं और कम से कम दिल्ली के दो अस्पतालों में तो ऑक्सीजन की सप्लाई रुक जाने से मरीज़ों की मौत हो गई.',\n",
       "  'कोरोना संक्रमितों के परिजन सोशल मीडिया पर लोगों से अस्पताल में बेड, ऑक्सीजन सिलेंडर और वेंटिलेटर के लिए गुहार लगा रहे हैं.',\n",
       "  'कोरोना वायरसः कमज़ोर होते इम्यून सिस्टम को कैसे बचाएं?',\n",
       "  'कोरोना की टेस्ट करने वाले लैब की हालत भी बहुत ख़राब हैं क्योंकि टेस्ट कराने वालों की संख्या रोज़ाना बढ़ रही है और इस कारण टेस्ट के नतीजे आने में कम से कम 3-4 दिन लग रहे हैं.',\n",
       "  'श्मशान घाट में शवों का आना लगा हुआ है और वहां 24 घंटे दाह संस्कार किया जा रहा है.',\n",
       "  'इमेज स्रोत, Getty Images',\n",
       "  'सरकार पर आरोप है कि वो कोरोना से मरने वालों की संख्या को कम करके बता रही है.',\n",
       "  'दिल्ली के अलावा दूसरे शहरों में भी कम-ओ-बेश यही नज़ारा है. अभी तक आधिकारिक रूप से भारत में कोरोना संक्रमितों की संख्या एक करोड़ 70 लाख है और मरने वालों की संख्या एक लाख 92 हज़ार हो गई है.',\n",
       "  'लेकिन इसकी बहुत ज़्यादा आशंका है कि यह आंकड़े सही नहीं हैं और मरने वालों की संख्या इससे कहीं ज़्यादा है.',\n",
       "  'भारत की आबादी इतनी ज़्यादा है और लॉजिस्टिक की इतनी समस्या है कि सभी कोरोना मरीज़ों का टेस्ट करना और मरने वालों का सही-सही रिकॉर्ड रखना बहुत मुश्किल है. इसीलिए यूरोप और अमेरिका की तुलना में भारत में कोरोना की समस्या का सही आकलन करना बहुत मुश्किल है.',\n",
       "  'इमेज स्रोत, Getty Images',\n",
       "  'ऑक्सीजन की कमी के कारण बहुत लोगों की मौत हो गई जो कि शायद बच सकते थे',\n",
       "  'जेम्स गैलाघर कहते हैं, \"दुख की बात है कि अगले कुछ हफ़्तों में हालात और ख़राब होंगे. एक सबक़ जो हमने बार-बार सीखा है वो ये है कि संक्रमितों की संख्या बढ़ने का मतलब है कि कुछ हफ़्तों के बाद मरने वालों की संख्या में भी इज़ाफ़ा होगा.\"',\n",
       "  'वो कहते हैं, \"अगर भारत किसी तरह वायरस को फैलने से रोक भी लेता है तो भी मरने वालों की संख्या बढ़ती रहेगी क्योंकि इतनी अधिक संख्या में लोग पहले से ही संक्रमित हो चुके हैं. अभी तो इस बात के भी कोई आसार नहीं हैं कि संक्रमितों की संख्या में कमी आ रही है. संक्रमितों की संख्या कितनी बढ़ेगी यह इस बात पर निर्भर करता है कि लॉकडाउन और वैक्सीनेशन से कितनी सफलता मिलती है.\\'\\'',\n",
       "  'कोरोना से जान गंवाने वालों के अंतिम संस्कार के लिए भी लंबी वेटिंग है',\n",
       "  'यह याद रखना चाहिए कि भारत में अभी तक ना ही संक्रमण का पीक आया है और ना ही मृतकों का. जॉन्स हॉपकिन्स यूनिवर्सिटी के अनुसार 26 अप्रैल तक अमेरिका में तीन करोड़ 20 लाख लोग संक्रमित हो चुके हैं और पाँच लाख 72 हज़ार से ज़्यादा लोग मारे जा चुके है .',\n",
       "  'हर 10 लाख की आबादी पर मरने वालों की संख्या के हिसाब से भी भारत अभी यूरोप और लैटिन अमेरिका के कई देशों की तुलना में पीछे है.',\n",
       "  'लेकिन भारत की आबादी इतनी ज़्यादा है और हाल के दिनों में संक्रमितों और इससे मरने वालों की संख्या में इस क़दर इज़ाफ़ा हुआ है कि इससे दुनिया भर को चिंता हो रही है.',\n",
       "  'संक्रमित रोगों के एक विशेषज्ञ प्रोफ़ेसर गौतम मेनन ने बीबीसी को बताया कि \"हमने इस तरह के हालात इससे पहले कभी नहीं देखे जहां कि हेल्थ सिस्टम इतनी बड़ी संख्या में मरीजों के कारण पूरी तरह चरमरा जाए.\"',\n",
       "  'जब हेल्थ सिस्टम ही ध्वस्त हो जाए तो लोग कई कारणों से अधिक संख्या में मरने लगते हैं और इनकी मौत का ज़िक्र कोरोना से मरने वालों की लिस्ट में शामिल नहीं होता है.',\n",
       "  ' इसके अलावा भारत में स्वास्थ्य सेवाएं देने वालों के सामने भी इतनी बड़ी आबादी को सेवा देने की चुनौती होती है और भारत में कई लोग ऐसे हैं जिनको किसी भी तरह की कोई स्वास्थ्य सेवा हासिल नहीं है.',\n",
       "  'कोरोना महामारी एक वैश्विक ख़तरा है.',\n",
       "  'शुरुआत के दिनों से ही वैज्ञानिकों और स्वास्थ्य विशेषज्ञों ने कह दिया था कि हवाई यात्रा और अर्थव्यवस्था के ग्लोबल होने के कारण यह वायरस एक से दूसरे देश में फैल रहा है.',\n",
       "  'इमेज स्रोत, Getty Images',\n",
       "  'वैश्विक अर्थव्यवस्था और अंतरराष्ट्रीय यात्रा के कारण कोरोना वायरस की राष्ट्रीय सीमाओं में बांधकर नहीं रखा जा सकता है',\n",
       "  'राष्ट्रीय सीमाओं ने अभी तक इस वायरस को रोकने में कोई सफलता हासिल नहीं की है और यह व्यावहारिक भी नहीं है अगर असंभव नहीं है तो, कि यात्रा पर पूरी तरह पाबंदी लगा दी जाए या फिर सीमाओं को अनिश्चितकाल के लिए बंद कर दिया जाए.',\n",
       "  'इसलिए जो भारत में होता है वो निश्चित तौर पर दुनिया में भी फैलेगा, ख़ासकर के जब भारत इस बात पर गर्व करता है कि भारतीय या भारतीय मूल के सबसे ज़्यादा लोग दुनिया भर में फैले हुए हैं.',\n",
       "  'बुखार खांसी कोरोना है, कैसे पता चलेगा?',\n",
       "  'जेम्स गैलाघर कहते हैं, \"इस महामारी ने हमें ये सिखाया है कि एक देश की समस्या सभी की समस्या है. कोरोना वायरस सबसे पहले चीन के एक शहर (वुहान) में पाया गया था, लेकिन अब यह वायरस हर जगह फैल चुका है. भारत में कोरोना संक्रमितों की रिकॉर्ड नंबर में संख्या का मतलब है कि यहां से दूसरे देशों में भी संक्रमण फैल सकता है. इसीलिए कई देशों ने भारत से यात्रा पर पाबंदी लगा दी है और संक्रमितों की संख्या में इज़ाफ़ा होने के कारण वायरस के नए वैरिएंट्स को पैर पसारने में मदद मिलती है.\"',\n",
       "  'भारत में कोरोना के ख़राब होते हालात दुनिया भर में कोरोना के ख़िलाफ़ चल रही लड़ाई के लिए एक बुरी ख़बर हो सकती है.',\n",
       "  'कैम्ब्रिज यूनिवर्सिटी में क्लिनिकल बायोलोजी के प्रोफ़ेसर रवि गुप्ता कहते हैं, \"भारत की ज़्यादा आबादी और घनत्व सबसे बेहतरीन जगह है इस वायरस को म्यूटेशन के लिए प्रयोग करने का.\"',\n",
       "  'अगर वायरस को इतने बेहतरीन वातावरण में म्यूटेट करने का मौक़ा मिलता है तो फिर इससे वायरस की क्षमता में दुनिया भर में इ़ज़ाफ़ा हो जाएगा.',\n",
       "  'जेम्स कहते हैं, \"वायरस को म्यूटेट होने का जितना मौक़ा मिलेगा, उसे लोगों को संक्रमित करने का उतना ही ज़्यादा मौक़ा मिलेगा, यहा तक कि वो उन लोगों को भी संक्रमित कर सकता है जिन्होंने वैक्सीन लगवा ली है.\"',\n",
       "  'इमेज स्रोत, Getty Images',\n",
       "  'भारत की अधिक जनसंख्या और कम जगह में ज़्यादा लोगों के रहने के कारण भी इस महामारी को फैलने में मदद मिलती है.',\n",
       "  'यूके, ब्राज़ील और दक्षिण अफ़्रीका के नए वैरिएंट्स ने पहले ही दुनिया भर में फैलकर समस्या खड़ी कर रखी है और अब प्रोफ़ेसर मेनन भारत में नए वैरियंट्स की चेतावनी देते हुए कहते हैं, \"कुछ वायरस प्रोटीन से संबंधित होते हैं जिसके कारण उन वायरस को कोशिकाओं से जुड़ने का मौक़ा मिल जाता है और साथ ही वो एंटीबॉडीज़ के बंधन को भी कमज़ोर करने में सफल हो जाते हैं.\\'\\'',\n",
       "  '\"वायरस के वैरिएंट्स को फैलने से रोकना लगभग असंभव है. कोरोना वायरस का B.1.617 वैरिएंट जो सबसे पहले भारत में पाया गया था, अब भारत से बाहर दुनिया के कई देशों में देखा गया है और इसका संभवत: एक ही कारण है कि वो भारत से वहां गया है.\"',\n",
       "  'प्रोफ़ेसर मेनन चेतावनी देते हुए कहते हैं कि वायरस म्यूटेट करते रहेंगे और वो इम्यूनिटी से बचने के लिए भी रास्ता खोज लेंगे ताकि जो एक बार संक्रमित हो चुके हैं या जिन्होंने वैक्सीन लगवा ली है उनको भी संक्रमित कर सकें.',\n",
       "  'सवाल यह है कि वो कितनी जल्दी ऐसा कर सकते हैं.',\n",
       "  'प्रोफ़ेसर मेनन कहते हैं, \"दुनिया भर के विभिन्न वैरियंट्स के अध्ययन से हममलोग जानते हैं कि SARS-CoV-2 म्यूटेट कर सकता है ताकि वो ज़्यादा आसानी से फैल सके. अभी तक हमलोगों का मानना है कि वैक्सीन इन नए वैरियंट्स पर भी प्रभावी होती हैं लेकिन हो सकता है कि भविष्य में यह बदल जाए.\"',\n",
       "  'भारत में ऑक्सीजन की कमी को दूर करने के लिए अंतरराष्टीय मदद की जा रही है.',\n",
       "  'यूके ने वेंटिलेटर और ऑक्सीजन कंसेन्ट्रेटर्स भेजना शुरू कर दिया है और अमेरिका ने वैक्सीन बनाने के लिए काम आने वाले कच्चे पदार्थों के निर्यात पर से पाबंदी हटा ली है जिससे एस्ट्राज़ेनेका की वैक्सीन कोविशील्ड बनाने में मदद मिलेगी.',\n",
       "  'इमेज स्रोत, AFP',\n",
       "  'दिल्ली के कुछ अस्पतालों में ऑक्सीजन नहीं मिलने से कई कोरोना मरीज़ों की मौत हो गई',\n",
       "  'कई दूसरे देश भी भारत को मेडिकल स्टाफ़ और दूसरे मेडिकर उपकरण भेज रहे हैं.',\n",
       "  'भारत सरकार ने देश भर में 500 ऑक्सीजन जेनेरेशन प्लांट लगाने की मंज़ूरी दे दी है.',\n",
       "  'लेकिन इन सबसे कोरोना से होने वाली मौतों को रोका जा सकता है, कोरोना से होने वाले संक्रमण को नहीं.',\n",
       "  'दुनिया को इस वक़्त ज़रूरत है कि भारत वैक्सीनेशन की अपनी क्षमता बढ़ाए ताकि वो वायरस को दुनिया भर में फैलने से रोके.',\n",
       "  'जब इस महामारी की शुरुआत हुई थी तब भारत को इस पर क़ाबू पाने की उम्मीद थी और उसके कारण भी थे, क्योंकि जहां तक वैक्सीन का सवाल है भारत दुनिया में सबसे ज़्यादा वैक्सीन बनाता है.',\n",
       "  'भारत में टीकाकरण का बहुत बड़ा अभियान चलता है, दुनिया भर की 60 फ़ीसदी वैक्सीन भारत में बनती है और दुनिया भर के बड़े दवा निर्माताओं में से सीरम इंस्टीट्यूट ऑफ़ इंडिया (एसआईआई) समेत क़रीब आधे दर्जन का मुख्यालय तो भारत में ही है.',\n",
       "  'इमेज स्रोत, AFP',\n",
       "  'भारत में दुनिया का सबसे बड़े वैक्सीनेशन प्रोग्राम चल रहा है.',\n",
       "  'बीबीसी संवाददाता सौतिक बिस्वास के अनुसार, \"लेकिन इन सबके बावजूद कोरोना वायरस के ख़िलाफ़ वैक्सीनेशन में अप्रत्याशित चुनौती पैदा हो रही हैं.\"',\n",
       "  'भारत में कोरोना वायरस के ख़िलाफ़ दुनिया का सबसे बड़ा टीकाकरण अभियान 16 जनवरी को शुरू हुआ और जुलाई तक क़रीब 25 करोड़ लोगों को वैक्सीन देने का लक्ष्य रखा गया.',\n",
       "  'अभी तक सिर्फ़ 11 करोड़ 80 लाख लोगों को पहला डोज़ दिया जा सका है. यह भारत की आबादी का क़रीब नौ फ़ीसदी हैं.',\n",
       "  'सबसे पहले हेल्थवर्कर्स और फ़्रंटलाइन स्टाफ़ को वैक्सीन दी गई थी लेकिन अब 18 साल से अधिक उम्र के सभी लोगों को एक मई से वैक्सीन देने का फ़ैसला किया गया है.',\n",
       "  'लेकिन भारत की इतनी बड़ी आबादी को देखते हुए वैक्सीनेशन में दिक़्क़तें आ रही हैं. ',\n",
       "  'विशेषज्ञों का कहना है कि वैक्सीनेशन की रफ़्तार को तेज़ करनी होगी अगर भारत अपना लक्ष्य पूरा करना चाहता है तो.',\n",
       "  'सौतिक बिस्वास कहते हैं, \"अभी यह साफ़ नहीं है कि भारत के पास पर्याप्त मात्रा में वैक्सीन है या नहीं या उसके पास युवाओं को भी वैक्सीन देने की क्षमता है या नहीं.\"',\n",
       "  'इमेज स्रोत, Getty Images',\n",
       "  'उम्मीद है कि जुलाई तक भारत में 25 करोड़ लोगों को वैक्सीन लग जाएगी',\n",
       "  'जब तक इतनी बड़ी आबादी को वैक्सीन नहीं लग जाती है, तब तक यह पूरी दुनिया के लिए ख़तरा है.',\n",
       "  'प्रोफ़ेसर मेनन कहते हैं, \" कोरोना जैसी संक्रमण वाली बीमारियों की दिक़्क़त यह है कि यह महामारी किसी एक देश की समस्या नहीं है, कुछ देशों की भी नहीं है बल्कि यह तो सचमुच में एक वैश्विक समस्या है.\\'\\'',\n",
       "  'वो कहते हैं, \"हमें कोरोना के टेस्ट और वैक्सीनेशन के मामले में और अधिक अंतरराष्ट्रीय सहयोग के सहयोग की ज़रूरत है.\"',\n",
       "  'कोरोना महामारी की शुरुआत में ही पब्लिक हेल्थ के अधिकारियों और राजनेताओं ने कहा था कि, \"जबतक हर कोई सुरक्षित नहीं है उस वक़्त तक कोई सुरक्षित नहीं है.',\n",
       "  '(बीबीसी हिन्दी के एंड्रॉएड ऐप के लिए आप यहां क्लिक कर सकते हैं. आप हमें फ़ेसबुक, ट्विटर, इंस्टाग्राम और यूट्यूब पर फ़ॉलो भी कर सकते हैं.)',\n",
       "  '© 2021 BBC. बाहरी साइटों की सामग्री के लिए बीबीसी ज़िम्मेदार नहीं है. बाहरी साइटों का लिंक देने की हमारी नीति के बारे में पढ़ें.']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file = 'saved/extracted_file_1.json'\n",
    "with open(file, \"rb\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
